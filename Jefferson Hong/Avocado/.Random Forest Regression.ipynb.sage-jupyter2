{"backend_state":"init","connection_file":"/projects/79f0d46f-11ed-4ebe-8d2f-dc96b3f45fdf/.local/share/jupyter/runtime/kernel-6a3b7ef5-69fb-495a-b08e-2994d575e399.json","kernel":"python3-ubuntu","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"a33e51","input":"","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"d72d42","input":"import pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"63f047","input":"main()","output":{"0":{"data":{"iframe":"dfa1919e3fb2683ed2b4c0c2352f3b0b8781b77a"},"exec_count":10,"output_type":"execute_result"},"1":{"data":{"iframe":"815fdeb6444a88d5e3dd47c6f6c3ecd78fbbe75b"},"exec_count":10,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"f01ea0","input":"def set_up():\n    df = pd.read_csv('avocados.csv')\n    df = df.loc[((df['geography'] == 'Total U.S.') & (df['type'] == 'conventional'))]\n    df['date'] = pd.to_datetime(df['date'])\n    df['month'] = df['date'].apply(date_to_month)\n    df['day'] = df['date'].apply(date_to_day)\n    df = df[['average_price', 'year', 'month', 'day']]\n    return df","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"33b99a","input":"def train(df):\n    labels = df['average_price']\n\n    features = df.drop('average_price', axis=1)\n\n    train_features, test_features, train_labels, test_labels = train_test_split(\n        features, labels, test_size=0.2, random_state=42)\n\n    rf = RandomForestRegressor(n_estimators=1000, random_state=42)\n    rf.fit(train_features, train_labels)\n\n    display_test_features = test_features.apply(nums_to_date, axis=1)\n    display_df = pd.DataFrame(display_test_features, columns=['date'])\n    display_df['actual'] = test_labels\n    display_df['predict'] = rf.predict(test_features)\n    display_df = display_df.sort_values(by='date')\n\n    fig1 = px.scatter(display_df, x='date', y='actual')\n\n    fig2 = px.line(display_df, x='date', y='predict')\n    fig2.update_traces(line_color='orange')\n\n    fig3 = go.Figure(data=fig1.data + fig2.data)\n    fig3.show()\n\n    return rf","pos":3,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"5f398b","input":"def predict(rf):\n\n    predict_df = pd.DataFrame(pd.date_range(start='1-16-2021', end='1-16-2029', freq='8D'), columns=['date'])\n    predict_df['date'] = pd.to_datetime(predict_df['date'])\n    predict_df['year'] = predict_df['date'].apply(date_to_year)\n    predict_df['month'] = predict_df['date'].apply(date_to_month)\n    predict_df['day'] = predict_df['date'].apply(date_to_day)\n    other = predict_df.drop('date', axis=1)\n    predict_df['predict'] = rf.predict(other)\n\n    fig4 = px.line(predict_df, x='date', y='predict')\n    fig4.show()","pos":4,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"9ba656","input":"def date_to_year(date):\n    return date.year","pos":5,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"642133","input":"def date_to_month(date):\n    return date.month","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"1a3ee7","input":"def date_to_day(date):\n    return date.day","pos":7,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"68213c","input":"def nums_to_date(row):\n    return pd.to_datetime(str(row['year']) + str(row['month']) + str(row['day']), format='%Y%m%d')","pos":8,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"1ec72f","input":"def main():\n    df = set_up()\n    rf = train(df)\n    predict(rf)","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"ef7e0d","input":"# Random Forest Regression\n\nFirst algorithm created by Tin Kam Ho in 1995\n\nWhat it is: a supervised machine learning algorithm and uses ensemble learning method, can do both classification and regression\n\nis a bagging technique\n\ncombines multiple decision trees\n\nPros: one of the most accurate learning algorithms, runs efficiently on large databases, has effective method for estimating missing data\n\nCons: sometimes overfits for some datasets\n","pos":0,"type":"cell"}
{"id":0,"time":1655328494053,"type":"user"}
{"last_load":1655322837592,"type":"file"}